{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-mining on webscraped phone reviews (iPhone + Samsung)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group members:\n",
    "\n",
    "Allesandro Girelli\n",
    "\n",
    "Cyprien Nielly\n",
    "\n",
    "Katie Chang\n",
    "\n",
    "Sebastien Moeller\n",
    "\n",
    "Viktor Malesevic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "The aim of this project is to do text-mining and analysis on phone reviews from different webpages (Amazon, Reddit, Influenster, etc...) in order to provide advice to phone manufacturers on potential issues faced by customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Webscraping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to webscrape Amazon reviews, which we did on R using the 'rvest' package. The second set of reviews we scraped were Google Shopping reviews with the code explained below.\n",
    "\n",
    "The results is found in our csv file, 'Reviews.csv'. This file concatenates data from iPhone X, iPhone 8, and Samsung S8 reviews.\n",
    "\n",
    "###### Scrapping Google Shopping Reviews:\n",
    "To scrap the Google Shopping reviews we used the BeautifulSoup package, as well as url to html downloader urllib.request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request as urll\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the code is built is that we are given the url of the first page of reviews and the functions scrap all pages available for the product.\n",
    "\n",
    "The following function takes a url and scraps all reviews from one page only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def googlePageScrap(url):\n",
    "    # Initializing BeautifulSoup\n",
    "    page = urll.urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    # Saving the nodes containing the reviews and ratings\n",
    "    rev = soup.find_all('div', attrs={'class':'review-content'})\n",
    "    rat = soup.find_all('div', attrs={'class':'_OBj'})\n",
    "    \n",
    "    # Ratings need to be extracted from the soup\n",
    "    rating = []\n",
    "    for i in range(len(rat)):\n",
    "        # Convert to string otherwise .find() doesn't work\n",
    "        rat[i] = str(rat[i])\n",
    "        # Finding the index of the rating\n",
    "        idx = rat[i].find('aria-label=\"')+len('aria-label=\"')\n",
    "        # Save the rating in the rating list\n",
    "        rating.append(int(rat[i][idx]))\n",
    "    \n",
    "    # The first entry is the average rating between all, therefore we delete it\n",
    "    rating = rating[1:]\n",
    "    \n",
    "    # Building the output\n",
    "    output = []\n",
    "    for i in range(len(rev)):\n",
    "        # Building meta data\n",
    "        meta = []\n",
    "        meta.append(rating[i])\n",
    "        # Reviews can use the function .text to extract the actual reviews\n",
    "        meta.append(rev[i].text[1:-20])\n",
    "        # Save meta data with the comment ( Rating + Review )\n",
    "        output.append(meta)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to go to the next page, we need to know how many pages there are. The `googleMaxPage(url)` function takes a url of a page of reviews as an input and returns the total number of pages of reviews. This is because only 10 reviews are displayed per page and we want as many reviews as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the number of pages of reviews that need to be visited\n",
    "def googleMaxPage(url):\n",
    "    page = urll.urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    maxPage = soup.find('span', attrs={'class':'pag-n-to-n-txt'})\n",
    "    maxPage = re.sub('[^0-9]','', maxPage.text[7:])\n",
    "    # This returns the total number of reviews\n",
    "    maxPage = int(maxPage)\n",
    "    # There are 10 reviews per page\n",
    "    maxPage = int(maxPage/10)-1\n",
    "    \n",
    "    return maxPage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using the following function we are able to visit each page of reviews and scrap the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scraps all reviews starting from page 1 as the input url\n",
    "def googleScrap(url):\n",
    "    \n",
    "    maxPage = googleMaxPage(url)\n",
    "    output = googlePageScrap(url)\n",
    "    \n",
    "    # Go to each page of reviews and add them to the output list\n",
    "    for i in range(maxPage):\n",
    "        urlPage = str(url + ',rstart:'+ str(i+1) +'0')\n",
    "        new = googlePageScrap(urlPage)\n",
    "        output = output + new\n",
    "        print(i+1,' / ',maxPage)\n",
    "    \n",
    "    # Convert the list into a pandas dataframe\n",
    "    output_df = pd.DataFrame(output)\n",
    "    output_df.columns = ['stars', 'comments']\n",
    "\n",
    "    return output_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual scrapping was done on the following URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.google.com/shopping/product/8330308525491645368/reviews?output=search&q=apple+iphone+8&prds=paur:ClkAsKraX0HAK8DTxuQ7a_QLy1VVmmdGjqus04Pco-mYuwDAnhwY-2yRVwjDEGi_xEsNVx11gFrfhnTT-NU5F1Cv8xkFN2t2KRFYe2S0bJHgJvnYxGmE7Xr8KxIZAFPVH73QWHZfxejgLJJNz1emAuExXPnAxg,rsort:1'\n",
    "iPhone8 = googleScrap(url)\n",
    "\n",
    "url = 'https://www.google.com/shopping/product/5196767965601398683/reviews?output=search&q=iphone+x&oq=iphone+x&prds=paur:ClkAsKraX6xXlTCTDvTg5n66BfqjZtUzj5mRPstz9QYmLjncZZBAQRRtobM8Pe5XLEZX0CP8x5UxXIzT52WhOhO2moZSRoKU0aTE6QE0f-R3zq1xhh45Jvza8BIZAFPVH70FzB4_QX4D05ZaAMc8F9sjUFRwvg,rsort:1'\n",
    "iPhoneX = googleScrap(url)\n",
    "\n",
    "url = 'https://www.google.com/shopping/product/2874873357294577697/reviews?output=search&q=galaxy+s8&oq=galaxy+s8&prds=paur:ClkAsKraX4MdXEv-XobV-tsudUmMvrTaF0oUQFrnUCBf-gngBeSUnGe1TQzRN-qEvUxg11H4haqP6POwtI-P9rAtftKbUh-e4yFNzeeFNldak82GgWHBlGI__xIZAFPVH72dPmpO1V1eoP7Y9BbJQh6EoOBh5Q,rsort:1'\n",
    "samsungS8 = googleScrap(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews were exported to csv files to be combined with the Amazon reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iPhoneX.to_csv('GoogleiPhoneX.csv')\n",
    "\n",
    "iPhone8.to_csv('GoogleiPhone8.csv')\n",
    "\n",
    "samsungS8.to_csv('GoogleSamsungS8.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the data\n",
    "\n",
    "Now that we have all our reviews we combine them into one csv file to be used in part 2.\n",
    "\n",
    "We begin by importing all csv files, merg the data to follow the same format, combine everything into a data frame and then export the information to `Reviews.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data0 = pd.read_csv('AmazonSamsungS8.csv', index_col = 0)\n",
    "data1 = pd.read_csv('AmazoniPhone8.csv', index_col = 0)\n",
    "data2 = pd.read_csv('AmazoniPhoneX.csv', index_col = 0)\n",
    "data3 = pd.read_csv('GoogleSamsungS8.csv', index_col = 0)\n",
    "data4 = pd.read_csv('GoogleiPhone8.csv', index_col = 0)\n",
    "data5 = pd.read_csv('GoogleiPhoneX.csv', index_col = 0)\n",
    "\n",
    "# Unifying format to merge meta data\n",
    "data0 = pd.DataFrame(data0[['comments', 'stars']])\n",
    "data0['source'] = 'Amazon'\n",
    "data0['product'] = 'Samsung S8'\n",
    "data0 = data0[['source', 'product', 'comments', 'stars']]\n",
    "\n",
    "data1 = pd.DataFrame(data1[['comments', 'stars']])\n",
    "data1['source'] = 'Amazon'\n",
    "data1['product'] = 'iPhone 8'\n",
    "data1 = data1[['source', 'product', 'comments', 'stars']]\n",
    "\n",
    "data2 = pd.DataFrame(data2[['comments', 'stars']])\n",
    "data2['source'] = 'Amazon'\n",
    "data2['product'] = 'iPhone X'\n",
    "data2 = data1[['source', 'product', 'comments', 'stars']]\n",
    "\n",
    "data3 = pd.DataFrame(data3[['comments', 'stars']])\n",
    "data3['source'] = 'Google Shopping'\n",
    "data3['product'] = 'Samsung S8'\n",
    "data3 = data3[['source', 'product', 'comments', 'stars']]\n",
    "\n",
    "data4 = pd.DataFrame(data4[['comments', 'stars']])\n",
    "data4['source'] = 'Google Shopping'\n",
    "data4['product'] = 'iPhone 8'\n",
    "data4 = data4[['source', 'product', 'comments', 'stars']]\n",
    "\n",
    "data5 = pd.DataFrame(data5[['comments', 'stars']])\n",
    "data5['source'] = 'Google Shopping'\n",
    "data5['product'] = 'iPhone X'\n",
    "data5 = data5[['source', 'product', 'comments', 'stars']]\n",
    "\n",
    "data6 = pd.DataFrame(data6[['CommentBox_Content', 'CommentBox_Rating']])\n",
    "data6.columns = ['comments', 'stars']\n",
    "data6['source'] = 'Influenster'\n",
    "data6['product'] = 'iPhone X'\n",
    "data6 = data6[['source', 'product', 'comments', 'stars']]\n",
    "\n",
    "group2Meta = pd.concat([data0, data1, data2, data3, data4, data5, data6])\n",
    "\n",
    "group2Meta.to_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Pre-processing the webscraped data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before reading the data we import some usefull libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pandas for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# nltk for all text data pre-processing\n",
    "\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: the nltk package needs to be download thanks to the command '`nltk.download()`' which then opens a window. On this window click on 'all packages' and then 'download'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the dataset:\n",
    "\n",
    "As the reviews come from different sources and contain characters such as emojis we need to specify the encoding option as the default can no longer interpret the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Reviews.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>product</th>\n",
       "      <th>comments</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Samsung S8</td>\n",
       "      <td>BEWARE!99% of the negative reviews are SELLER ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Samsung S8</td>\n",
       "      <td>So far the best phone I ever had. Man it's be...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Samsung S8</td>\n",
       "      <td>I was skeptical about buying this phone off Am...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Samsung S8</td>\n",
       "      <td>This phone should be a no-brainer. Easily the ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Samsung S8</td>\n",
       "      <td>I haven't owned a Galaxy phone since the Galax...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  source     product  \\\n",
       "0           1  Amazon  Samsung S8   \n",
       "1           2  Amazon  Samsung S8   \n",
       "2           3  Amazon  Samsung S8   \n",
       "3           4  Amazon  Samsung S8   \n",
       "4           5  Amazon  Samsung S8   \n",
       "\n",
       "                                            comments  stars  \n",
       "0  BEWARE!99% of the negative reviews are SELLER ...    5.0  \n",
       "1   So far the best phone I ever had. Man it's be...    5.0  \n",
       "2  I was skeptical about buying this phone off Am...    5.0  \n",
       "3  This phone should be a no-brainer. Easily the ...    3.0  \n",
       "4  I haven't owned a Galaxy phone since the Galax...    4.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>product</th>\n",
       "      <th>comments</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Samsung S8</td>\n",
       "      <td>BEWARE!99% of the negative reviews are SELLER ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Samsung S8</td>\n",
       "      <td>So far the best phone I ever had. Man it's be...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Samsung S8</td>\n",
       "      <td>I was skeptical about buying this phone off Am...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Samsung S8</td>\n",
       "      <td>This phone should be a no-brainer. Easily the ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Samsung S8</td>\n",
       "      <td>I haven't owned a Galaxy phone since the Galax...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source     product                                           comments  \\\n",
       "0  Amazon  Samsung S8  BEWARE!99% of the negative reviews are SELLER ...   \n",
       "1  Amazon  Samsung S8   So far the best phone I ever had. Man it's be...   \n",
       "2  Amazon  Samsung S8  I was skeptical about buying this phone off Am...   \n",
       "3  Amazon  Samsung S8  This phone should be a no-brainer. Easily the ...   \n",
       "4  Amazon  Samsung S8  I haven't owned a Galaxy phone since the Galax...   \n",
       "\n",
       "   stars  \n",
       "0    5.0  \n",
       "1    5.0  \n",
       "2    5.0  \n",
       "3    3.0  \n",
       "4    4.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5746.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.320745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.247721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             stars\n",
       "count  5746.000000\n",
       "mean      4.320745\n",
       "std       1.247721\n",
       "min       1.000000\n",
       "25%       4.000000\n",
       "50%       5.000000\n",
       "75%       5.000000\n",
       "max       5.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So far we have a dataset of 5700 reviews, composed of 4 columns:\n",
    "\n",
    "The source: Amazon\n",
    "\n",
    "The product: iPhone 8, iPhone X or Samsung S8\n",
    "\n",
    "The comment/review: raw text written by the customer\n",
    "\n",
    "The rating: from 1 to 5 stars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the moment we will only focus on the comments for each phone model (without rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commentsiX = data[data['product'] == 'iPhone X']\n",
    "commentsi8 = data[data['product'] == 'iPhone 8']\n",
    "commentsS8 = data[data['product'] == 'Samsung S8']\n",
    "\n",
    "commentsiX = commentsiX['comments']\n",
    "commentsi8 = commentsi8['comments']\n",
    "commentsS8 = commentsS8['comments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Removing unnecessary characters and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tokenizing comments into monograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-adfa53d8c3ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# nltk's tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtkzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreserve_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_handles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtkzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'comments' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Lemmatizing the monograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Creation of a Term Frequency & Inverse Term Frequency matrix (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Non-negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Topic extraction with Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
