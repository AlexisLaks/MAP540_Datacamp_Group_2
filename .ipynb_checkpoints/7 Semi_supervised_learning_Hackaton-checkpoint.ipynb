{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi supervised learning \n",
    "\n",
    "#### aim of this notebook : build a classifer for defaults (that is classify a comment as a review related to a default, issue)\n",
    "### first build a classifier in supervised approach using labeled data \n",
    "### second build a classifer based on labeled data + unlabeled data to which we propagated labels \n",
    "\n",
    "This time we want to build a  classifier that classifies the comment in one or more of this categories:\n",
    "\n",
    "- screen\n",
    "- software_bugs\n",
    "- locking_system\n",
    "- system\n",
    "- apps_update\n",
    "- battery_life_charging\n",
    "- customerservice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook # progress bars in Jupyter\n",
    "#import newspaper # download newspapers' data easily\n",
    "from time import time # measure the computation time of a python code\n",
    "import pandas as pd # the most basic & powerful data manipulation tool\n",
    "import numpy as np # Here, mostly used for np.nan\n",
    "import langdetect # detect the language of text\n",
    "import stop_words # handles stop words in many languages without having to rebuild them everytime\n",
    "import spacy # NLP library for POS tagging\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import itertools\n",
    "# For spacy use \"pip install spacy\", then \"python -m spacy download en\" to download English text mining modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "#tqdm_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('labeled_data.csv', engine='python') # label data only -> used for supervised model \n",
    "\n",
    "dfu = pd.read_csv('data_unlabeled.csv', encoding = 'utf-8') \n",
    "# unlabeled data -> used to together with lable data for semi supervised learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10997, 15)\n",
      "                                               text  apps_update  \\\n",
      "0  dope video brian iâve been subscribe for years          0.0   \n",
      "\n",
      "   battery_life_charging  battery_overheat  camera  connectivity  \\\n",
      "0                    0.0               0.0     0.0           0.0   \n",
      "\n",
      "   customerservice  locking_system  memory_storage  screen  software_bugs  \\\n",
      "0              0.0             0.0             0.0     0.0            0.0   \n",
      "\n",
      "   sound  system  water_damage  issue  \n",
      "0    0.0     0.0           0.0    0.0  \n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apps_update                82\n",
       "battery_life_charging     147\n",
       "battery_overheat           22\n",
       "camera                    100\n",
       "connectivity              109\n",
       "customerservice           109\n",
       "locking_system            206\n",
       "memory_storage            156\n",
       "screen                    316\n",
       "software_bugs             140\n",
       "sound                      43\n",
       "system                    343\n",
       "water_damage                6\n",
       "issue                    1498\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[c for c in df.columns if c not in ['text', 'tokens']]].sum().map(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder**: we want only these:\n",
    "\n",
    "- screen\n",
    "- software_bugs\n",
    "- locking_system\n",
    "- system\n",
    "- apps_update\n",
    "- battery_life_charging\n",
    "- customerservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df['issue']\n",
    "del df['water_damage']\n",
    "del df['sound']\n",
    "del df['battery_overheat']\n",
    "del df['connectivity']\n",
    "del df['memory_storage']\n",
    "del df['camera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apps_update               82\n",
       "battery_life_charging    147\n",
       "customerservice          109\n",
       "locking_system           206\n",
       "screen                   316\n",
       "software_bugs            140\n",
       "system                   343\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[c for c in df.columns if c not in ['text', 'tokens']]].sum().map(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we have for 'screen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>apps_update</th>\n",
       "      <th>battery_life_charging</th>\n",
       "      <th>customerservice</th>\n",
       "      <th>locking_system</th>\n",
       "      <th>screen</th>\n",
       "      <th>software_bugs</th>\n",
       "      <th>system</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it crashes for nothing and strikes with someth...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>only drawback is that it's very difficult for ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>have horizontal lines that run across the scre...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>a small drop the screen cracked and we had a c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>only thing is that i\u0019ve got big hands so i mis...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  apps_update  \\\n",
       "5    it crashes for nothing and strikes with someth...          0.0   \n",
       "19   only drawback is that it's very difficult for ...          0.0   \n",
       "133  have horizontal lines that run across the scre...          0.0   \n",
       "156  a small drop the screen cracked and we had a c...          0.0   \n",
       "217  only thing is that i\u0019ve got big hands so i mis...          0.0   \n",
       "\n",
       "     battery_life_charging  customerservice  locking_system  screen  \\\n",
       "5                      0.0              0.0             0.0     1.0   \n",
       "19                     0.0              0.0             0.0     1.0   \n",
       "133                    0.0              0.0             0.0     1.0   \n",
       "156                    0.0              0.0             0.0     1.0   \n",
       "217                    0.0              0.0             0.0     1.0   \n",
       "\n",
       "     software_bugs  system  \n",
       "5              1.0     0.0  \n",
       "19             0.0     0.0  \n",
       "133            0.0     0.0  \n",
       "156            0.0     0.0  \n",
       "217            0.0     0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.screen==1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features and prepare the data into a NMF matrix before Machine Learning\n",
    "\n",
    "### one important thing to have in mind when building a model : to make feature engineering separately on train and test. If you don't do that, you will incoporate info from the test set into the train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim import corpora\n",
    "import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "#nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function to clean and process the reviews\n",
    "def cleaning_data(df) :\n",
    "    STOPWORDS = stop_words.get_stop_words(language='en')\n",
    "    #df.drop_duplicates(inplace= True) # Drop duplicated sentences\n",
    "    df = df[~df['text'].isnull()] # Remove empty sentences\n",
    "        \n",
    "    # Remove special characters and punctucation\n",
    "    df['clean_review']= [ re.sub('[^A-Za-z]+',' ', e ) for e in df['text'].apply(lambda x : x.lower())]\n",
    "    \n",
    "    # Remove empty clean_review\n",
    "    df = df[~df['clean_review'].isnull()]\n",
    "    df = df[~(df['clean_review']==' ')]\n",
    "    df.reset_index(inplace=True, drop=True) # Reset index\n",
    "    \n",
    "    df['tokens'] = df['clean_review'].map(word_tokenize)\n",
    "    df['nb_tokens'] = df['tokens'].map(len)\n",
    "    \n",
    "    ## keep only sentences with at least 3 tokens\n",
    "    df = df[df['nb_tokens']>2]\n",
    "    \n",
    "    # remove stopwords\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [i for i in x if i not in STOPWORDS])\n",
    "\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    df['stemmed_text'] = df[\"tokens\"].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    df['joined_stemmed_text'] = [' '.join(word for word in word_list) for word_list in df.stemmed_text ]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## split between train and test at the beginning \n",
    "# we will use the same test set for supervised and semi supervised learning, so that we can compare the performances of \n",
    "# both approaches \n",
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing data\n",
    "df_train = cleaning_data(df_train)\n",
    "df_test = cleaning_data(df_test)\n",
    "dfu = cleaning_data(dfu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17547\n"
     ]
    }
   ],
   "source": [
    "## in order to have the same features on train data sets (for both supervised and semi-sup) and test data sets\n",
    "# build the tf idf with vocab which is the union the 3 above data sets \n",
    "vocab = list(set(itertools.chain(*dfu.stemmed_text.tolist()))|set(itertools.chain(*df_test.stemmed_text.tolist()))|set(itertools.chain(*df_train.stemmed_text.tolist())))\n",
    "vocab_dict = dict((y, x) for x, y in enumerate(vocab))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build tf idf matrix separately for train and test and unlabeled data sets \n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, ngram_range=(1,3), use_idf=True, vocabulary = vocab_dict)\n",
    "td_train = tfidf_vectorizer.fit_transform(df_train.joined_stemmed_text.tolist())\n",
    "td_test = tfidf_vectorizer.transform(df_test.joined_stemmed_text.tolist())\n",
    "td_u = tfidf_vectorizer.transform(dfu.joined_stemmed_text.tolist())\n",
    "#td_test = tfidf_vectorizer.fit_transform(df_test.joined_stemmed_text.tolist())\n",
    "#td_u = tfidf_vectorizer.fit_transform(dfu.joined_stemmed_text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#td_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried without the NMF. Just a tf-idf matrix as X. But it did not work. It seems like we should keep NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train = pd.DataFrame(td_train)\n",
    "#X_test = pd.DataFrame(td_test)\n",
    "#X_u = pd.DataFrame(td_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## same with NMF dimensionality reduction \n",
    "## the NMF decomposes this Term Document matrix into the product of 2 smaller matrices: W and H\n",
    "n_dimensions = 50 # This can also be interpreted as topics in this case. This is the \"beauty\" of NMF. 10 is arbitrary\n",
    "nmf_model = NMF(n_components=n_dimensions, random_state=42, alpha=.1, l1_ratio=.5)\n",
    "\n",
    "#X_u = pd.DataFrame(nmf_model.fit_transform(td_u))\n",
    "\n",
    "X_train = pd.DataFrame(nmf_model.fit_transform(td_train))\n",
    "X_test = pd.DataFrame(nmf_model.transform(td_test))\n",
    "X_u = pd.DataFrame(nmf_model.transform(td_u))\n",
    "#X_test = pd.DataFrame(nmf_model.fit_transform(td_test))\n",
    "#X_u = pd.DataFrame(nmf_model.fit_transform(td_u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I decided to reduce the number of topics to 10 instead of 50 to see if it improves our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046061</td>\n",
       "      <td>0.063311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.031370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045891</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.021767</td>\n",
       "      <td>0.031431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.082053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.014097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056771</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034142</td>\n",
       "      <td>0.039244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.031641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7626</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7627</th>\n",
       "      <td>0.028560</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7629</th>\n",
       "      <td>0.020274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7630</th>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.035013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7631</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7632</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7633</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073453</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>0.030667</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7635</th>\n",
       "      <td>0.018410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054120</td>\n",
       "      <td>0.061891</td>\n",
       "      <td>0.013326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7636</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034736</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>0.043492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080185</td>\n",
       "      <td>0.093954</td>\n",
       "      <td>0.132161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>0.036506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7643</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7644</th>\n",
       "      <td>0.053369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7645</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7646</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.032979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>0.019222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7651</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7652</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7653</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7654</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105489</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7656 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.046061  0.063311  0.000000  0.069575  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5     0.031370  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6     0.021767  0.031431  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8     0.000000  0.000000  0.134151  0.000000  0.144832  0.000000  0.000000   \n",
       "9     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10    0.000000  0.000000  0.000000  0.000000  0.000000  0.108797  0.000000   \n",
       "11    0.000000  0.035717  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "12    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "13    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "14    0.000000  0.033304  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "16    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.023528   \n",
       "17    0.000000  0.000000  0.000000  0.026176  0.000000  0.000000  0.000000   \n",
       "18    0.019917  0.000000  0.000000  0.000000  0.000000  0.031668  0.000000   \n",
       "19    0.000000  0.027533  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "20    0.000000  0.000000  0.070945  0.000000  0.075331  0.000000  0.000000   \n",
       "21    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "22    0.000000  0.000000  0.000000  0.000000  0.000000  0.036893  0.000000   \n",
       "23    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "24    0.014097  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "25    0.016758  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "26    0.000000  0.000000  0.000000  0.034142  0.039244  0.000000  0.000000   \n",
       "27    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "28    0.000000  0.000000  0.000000  0.000000  0.000000  0.032188  0.000000   \n",
       "29    0.031641  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7626  0.000000  0.000482  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7627  0.028560  0.020620  0.000000  0.023558  0.000000  0.000000  0.000000   \n",
       "7628  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7629  0.020274  0.000000  0.000000  0.000000  0.000000  0.031072  0.000000   \n",
       "7630  0.024215  0.035013  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7631  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7632  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7633  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7634  0.030667  0.000223  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7635  0.018410  0.000000  0.000000  0.000000  0.000000  0.028656  0.000000   \n",
       "7636  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7637  0.043492  0.000000  0.000000  0.080185  0.093954  0.132161  0.000000   \n",
       "7638  0.022035  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7639  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7640  0.036506  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7641  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7642  0.000000  0.045648  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7643  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7644  0.053369  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7645  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.004774   \n",
       "7646  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7647  0.000345  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7648  0.000000  0.038306  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7649  0.000367  0.032979  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7650  0.019222  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7651  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7652  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7653  0.000000  0.001585  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7654  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7655  0.000000  0.000521  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            7         8         9     ...      40        41        42  \\\n",
       "0     0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "1     0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.001930    ...     0.0  0.000000  0.000000   \n",
       "3     0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "5     0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "6     0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7     0.000000  0.000000  0.000000    ...     0.0  0.003715  0.000000   \n",
       "8     0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "9     0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "10    0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "11    0.059265  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "12    0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "13    0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "14    0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "15    0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "16    0.000000  0.000000  0.000787    ...     0.0  0.000000  0.115741   \n",
       "17    0.000000  0.000000  0.007128    ...     0.0  0.000000  0.000000   \n",
       "18    0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "19    0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "20    0.084231  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "21    0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "22    0.000000  0.000000  0.000329    ...     0.0  0.000000  0.000000   \n",
       "23    0.000908  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "24    0.000000  0.000000  0.000336    ...     0.0  0.000000  0.000000   \n",
       "25    0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "26    0.000000  0.001686  0.000000    ...     0.0  0.000000  0.000000   \n",
       "27    0.000000  0.000000  0.000000    ...     0.0  0.000000  0.100074   \n",
       "28    0.000000  0.000000  0.000000    ...     0.0  0.072671  0.000000   \n",
       "29    0.000000  0.000000  0.000000    ...     0.0  0.102359  0.000000   \n",
       "...        ...       ...       ...    ...     ...       ...       ...   \n",
       "7626  0.000000  0.002255  0.001190    ...     0.0  0.000000  0.000000   \n",
       "7627  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7628  0.000000  0.000449  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7629  0.000000  0.000000  0.050902    ...     0.0  0.000000  0.000000   \n",
       "7630  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7631  0.045417  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7632  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7633  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7634  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7635  0.000000  0.022813  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7636  0.000000  0.034736  0.010017    ...     0.0  0.000000  0.137514   \n",
       "7637  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7638  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7639  0.001898  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7640  0.000000  0.007395  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7641  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7642  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7643  0.000000  0.000000  0.000000    ...     0.0  0.053048  0.000000   \n",
       "7644  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7645  0.000000  0.000000  0.001209    ...     0.0  0.000000  0.000000   \n",
       "7646  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7647  0.000918  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7648  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7649  0.000000  0.010488  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7650  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7651  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7652  0.000000  0.000000  0.000391    ...     0.0  0.000000  0.000000   \n",
       "7653  0.000000  0.017404  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7654  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "7655  0.000000  0.000000  0.000000    ...     0.0  0.000000  0.000000   \n",
       "\n",
       "            43        44        45        46        47        48        49  \n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1     0.000000  0.000000  0.140653  0.000000  0.147177  0.000000  0.000000  \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.067534  0.000000  0.004695  \n",
       "5     0.000114  0.000000  0.000000  0.062277  0.000000  0.045891  0.000000  \n",
       "6     0.004076  0.082053  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.009819  \n",
       "8     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "9     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "10    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "11    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "12    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "13    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "14    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "15    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "16    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "17    0.000000  0.000000  0.000000  0.000095  0.000000  0.000000  0.000000  \n",
       "18    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "19    0.000000  0.000000  0.000000  0.000000  0.058459  0.000000  0.000000  \n",
       "20    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "21    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "22    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "23    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "24    0.000000  0.000000  0.000000  0.000000  0.000000  0.056771  0.000000  \n",
       "25    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "26    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "27    0.000000  0.000000  0.000000  0.000000  0.000000  0.006039  0.000000  \n",
       "28    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "29    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7626  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.002199  \n",
       "7627  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7628  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7629  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7630  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7631  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7632  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7633  0.000000  0.000000  0.000000  0.166375  0.000000  0.073453  0.000000  \n",
       "7634  0.002263  0.000000  0.000000  0.000000  0.000000  0.000000  0.000328  \n",
       "7635  0.073836  0.000000  0.000000  0.000000  0.054120  0.061891  0.013326  \n",
       "7636  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7637  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7638  0.000000  0.000000  0.000000  0.000000  0.000000  0.000835  0.000000  \n",
       "7639  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7640  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7641  0.058847  0.000000  0.000000  0.000000  0.000000  0.000000  0.004554  \n",
       "7642  0.123958  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7643  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7644  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.002413  \n",
       "7645  0.000000  0.003685  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7646  0.000000  0.000000  0.000000  0.000000  0.145443  0.000000  0.000000  \n",
       "7647  0.000000  0.000000  0.000000  0.000000  0.019687  0.000000  0.000000  \n",
       "7648  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7649  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7650  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.003009  \n",
       "7651  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7652  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7653  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7654  0.000000  0.000000  0.000000  0.000000  0.000000  0.105489  0.000000  \n",
       "7655  0.000000  0.000000  0.000000  0.000000  0.000000  0.011168  0.000000  \n",
       "\n",
       "[7656 rows x 50 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So far I've tried:\n",
    "\n",
    "- Keeping 'fit' to X_train, X_test and X_u gives very low performances (particularly for f1 for our relevant labeling. It basically labels 0 or only one of the testing data as 'relevant'.\n",
    "\n",
    "- Putting 'fit' only for X_train. Gives the best overall results: tf = 0.09 for the Normal classifier for our relevant topic. The unsupervised propagation with nn = 10 does not improve performance (it a actually decrease them if we consider the relevant category: 0.06. However, if we lower the threshold we get to 0.17\n",
    "\n",
    "- Increasing the the number of topics of NMF to 100 (instead of 50): It increases the performances: 0.11 for Normal Classifier. For unsupervised propagation it decreases f1 to 0.04.  If we lower the threshold we get 0.09\n",
    "\n",
    "NOTA: So far both last solutions give an overall f1 of 0.96 for Normal, unsupervised, and threshold reduced (against 0.80 for 'fit' eveywhere).\n",
    "\n",
    "- Putting 'fit' only for X_u (because higher number of comments) with topics = 50. Increases the performances: f1 = 0.11 for Normal (still with 0.96 overall).  But only 0.02 for unsupervised (still 0.96 overall). However: it increases the f1 of the lowered threshold to 0.19! (still 0.96 overall)\n",
    "\n",
    "#### -> Next steps: change nn to 20? Try to find a Classifier that puts more weight on the relevant category during the optimization.\n",
    "\n",
    "- With 'fit' only on X_train. Topics = 50. (Normal is the same of course) With nn = 20: f1 = 0.06 for unsupervised. (0.96 overall). However 0.22 for lower threshold! (0.96 overall)\n",
    "\n",
    "- Topics = 20, nn = 50: f1 = 0.11 for Normal (0.96 overall) 0.02 for unsupervised (0.96 overall) and 0.23 for lower threshold! (0.96 overall)\n",
    "\n",
    "- Topics = 20, nn = 5: f1 = 0.10 for unsupervised (0.96 overall) and only 0.10 with lowered threshold. (0.96 overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with \"screen first\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df_train.screen.map(int)\n",
    "y_test = df_test.screen.map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the labels for both train and test \n",
    "#for i in df.columns if i not in ['text', 'tokens']\n",
    "#    y_train[i] = df_train.columns[i].map(int)\n",
    "#    y_test[i] = df_test.columns[i].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7656 (Number of comments in X_train)\n",
      "222 (Number of relevant labels in X_train)\n",
      "3286 (Number of comments in X_test)\n",
      "94 (Number of relevant labels in X_test)\n"
     ]
    }
   ],
   "source": [
    "# lets look at the number of positive in the data sets \n",
    "print(len(X_train), '(Number of comments in X_train)')\n",
    "print(sum(y_train), '(Number of relevant labels in X_train)')\n",
    "\n",
    "print(len(X_test), '(Number of comments in X_test)')\n",
    "print(sum(y_test), '(Number of relevant labels in X_test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets estimate a gradient boosting classifier \n",
    "model = GradientBoostingClassifier(n_estimators=100, random_state=42, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here with 'screen' again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7432    2]\n",
      " [ 140   82]]\n",
      "[[3177   15]\n",
      " [  89    5]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, model.predict(X_train)))\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that only 5 comments are labeled as \"screen\" by our prediction model on the testing set. And 89 that should have been detected did not get detected! This is pretty pretty bad. The reason might be that our Gradient Boosting method focuses on optimizing the prediction error, which is not the metric that makes sense in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      3192\n",
      "          1       0.25      0.05      0.09        94\n",
      "\n",
      "avg / total       0.95      0.97      0.96      3286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### semi supervised learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPropagation(alpha=None, gamma=20, kernel='knn', max_iter=3000, n_jobs=1,\n",
       "         n_neighbors=10, tol=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "label_prop_model = LabelPropagation(kernel = 'knn', n_neighbors=10, max_iter = 3000)\n",
    "label_prop_model.fit(X_train, y_train)\n",
    "#label_prop_model.fit(pd.concat([X_train, X_test]), pd.concat([y_train, y_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What distance is used here? Because we are using a TF-IDF Matrix... Euclidian distance does not make sense.\n",
    "Here we are actually using it on the NMF. So the number of dimension is way lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    83522\n",
      "1      396\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_semi_proba = label_prop_model.predict_proba(X_u) # first column gives the proba of 0, second column gives the proba of 1 \n",
    "y_semi = pd.Series(label_prop_model.predict(X_u))\n",
    "print(y_semi.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    83918.000000\n",
       "mean         0.029544\n",
       "std          0.081550\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          0.900000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_1 = y_semi_proba[:,1] # get the proba of 1 \n",
    "pd.Series(proba_1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90943    13]\n",
      " [  535    83]]\n",
      "[[3184    8]\n",
      " [  91    3]]\n"
     ]
    }
   ],
   "source": [
    "# with n neigh = 10\n",
    "X_train_semi = pd.concat([X_train, X_u])\n",
    "y_train_semi = pd.concat([y_train, y_semi])\n",
    "model.fit(X_train_semi, y_train_semi)\n",
    "\n",
    "print(confusion_matrix(y_train_semi, model.predict(X_train_semi)))\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      3192\n",
      "          1       0.27      0.03      0.06        94\n",
      "\n",
      "avg / total       0.95      0.97      0.96      3286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We see that here the Label Propagation does not really improve our model... (or a bit only)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that with a 50% threshold it's maybe too strict for this case... Maybe we should lower this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88729   300]\n",
      " [ 1144  1401]]\n",
      "[[3157   35]\n",
      " [  82   12]]\n"
     ]
    }
   ],
   "source": [
    "# try to spread more labels (use thereshold lower than 0.5 in order to predict more labels)\n",
    "# here we spread the same proportion of 1 in the unlabeled data set as in the labeled train data set  \n",
    "y_semi_bis = pd.Series([1 if x > pd.Series(proba_1).quantile(q=1-np.mean(y_train)) else 0 for x in proba_1])\n",
    "y_train_semi_bis = pd.concat([y_train, y_semi_bis])\n",
    "model.fit(X_train_semi, y_train_semi_bis)\n",
    "print(confusion_matrix(y_train_semi_bis, model.predict(X_train_semi)))\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      3192\n",
      "          1       0.26      0.13      0.17        94\n",
      "\n",
      "avg / total       0.95      0.96      0.96      3286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lowering the threshold improves the f1 score for the category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets estimate a XG boosting classifier \n",
    "XGmodel = xgb.XGBClassifier(n_estimators=100, random_state=42, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7430    4]\n",
      " [ 198   24]]\n",
      "[[3188    4]\n",
      " [  93    1]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, XGmodel.predict(X_train)))\n",
    "print(confusion_matrix(y_test, XGmodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that only one comment was label as \"screen\" by our prediction model on the testing set. And 431 that should have been detected did not get detected! This is pretty pretty bad. The reason might be that our Gradient Boosting method focuses on optimizing the prediction error, which is not the metric that makes sense in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      3192\n",
      "          1       0.20      0.01      0.02        94\n",
      "\n",
      "avg / total       0.95      0.97      0.96      3286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, XGmodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### semi supervised learning combined to XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90955     1]\n",
      " [  617     1]]\n",
      "[[3191    1]\n",
      " [  94    0]]\n"
     ]
    }
   ],
   "source": [
    "# with n neigh = 10\n",
    "XGmodel.fit(X_train_semi, y_train_semi)\n",
    "\n",
    "print(confusion_matrix(y_train_semi, XGmodel.predict(X_train_semi)))\n",
    "print(confusion_matrix(y_test, XGmodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      3192\n",
      "          1       0.00      0.00      0.00        94\n",
      "\n",
      "avg / total       0.94      0.97      0.96      3286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, XGmodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This does not work. It does not label any comment as 'screen'..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88818   211]\n",
      " [ 1275  1270]]\n",
      "[[3165   27]\n",
      " [  84   10]]\n"
     ]
    }
   ],
   "source": [
    "# try to spread more labels (use thereshold lower than 0.5 in order to predict more labels)\n",
    "# here we spread the same proportion of 1 in the unlabeled data set as in the labeled train data set  \n",
    "y_semi_bis = pd.Series([1 if x > pd.Series(proba_1).quantile(q=1-np.mean(y_train)) else 0 for x in proba_1])\n",
    "y_train_semi_bis = pd.concat([y_train, y_semi_bis])\n",
    "XGmodel.fit(X_train_semi, y_train_semi_bis)\n",
    "print(confusion_matrix(y_train_semi_bis, XGmodel.predict(X_train_semi)))\n",
    "print(confusion_matrix(y_test, XGmodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      3192\n",
      "          1       0.27      0.11      0.15        94\n",
      "\n",
      "avg / total       0.95      0.97      0.96      3286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, XGmodel.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost performs worse than the normal GradientBoosting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
