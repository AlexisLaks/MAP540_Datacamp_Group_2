---
title: "Text mining"
output: html_notebook
---
### Preliminary step: importing the data

```{r}
df <- read.csv("group2.csv", row.names = 1)

df <- df[complete.cases(df), ]
df <- as.data.frame(df)
colnames(df) <- c("comment")
```
Our dataframe is ready

### First step: creating a corpus

```{r}
library(tm)
myCorpus <- Corpus(VectorSource(df$comment))
```

### Second step: ponctuation filter, etc

```{r}
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
#myCorpus <- tm_map(myCorpus, removeNumbers) dangerous because we might loose the cellphone model number
```

```{r}
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))

myCorpus <- tm_map(myCorpus, toSpace, "/|@|ù|š|ø|ˆ|ƒ|€|™|â|ã|\n|ð|ÿ|˜|\\|")
```

### Third step: remove white space

```{r}
myCorpus <- tm_map(myCorpus, stripWhitespace)
```

### Fourth step: remove stop words

```{r}
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, stripWhitespace)
```

Let's print the first comment.
```{r}
myCorpus$content[1]
```
It looks OK. 

### Sixth: tokenizing

We are going to create unigrams, bigrams and trigrams.
First try:
```{r}
BigramTokenizer <- function(x) unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)

dtm_unigrams <- DocumentTermMatrix(myCorpus)
inspect(dtm_unigrams[1:10, 1:10])

dtm_bigrams <- DocumentTermMatrix(myCorpus, control = list(tokenize = BigramTokenizer))
inspect(dtm_bigrams[1:10, 1:10])
```
The bigrams matrix is the same ... so it failed!

Other try with other function:
```{r}
library(quanteda)
myCorpus_1gram <- tokens(myCorpus$content)
```
It does not work. Let's do the analysis for unigrams. 

### Seventh step: lemantization

Before the TF-IDF analysis, we have to lemantize the unigrams.

```{r}
library(tm)
library(textstem)
for (word in dtm_unigrams$dimnames$Terms){
  word <- lemmatize_words(word)
}
```


### Eighth step: term frequency


To reduce the dimension of the DTM, we can remove the less frequent terms such that the sparsity is less than 0.99

```{r}
dtm_unigrams = removeSparseTerms(dtm_unigrams, 0.99)
dtm_unigrams
inspect(dtm_unigrams[4,1:10])
```

Let's draw a word cloud:

```{r}
library(wordcloud)
freq = data.frame(sort(colSums(as.matrix(dtm_unigrams)), decreasing=TRUE))
wordcloud(rownames(freq), freq[,1], max.words=100, colors= brewer.pal(5,"Dark2"))
```




