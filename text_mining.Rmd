---
title: "Text mining"
output: html_notebook
---
### Preliminary step: importing the data

```{r}
df_influenster <- read.csv("influenster_iphoneX.csv", sep = ",")

df_influenster <- df_influenster[complete.cases(df_influenster), ]

df_influenster <- as.data.frame(df_influenster)
```
Our dataframe is ready

### First step: creating a corpus

```{r}
library(tm)
myCorpus <- Corpus(VectorSource(df_influenster$CommentBox_Content))
```

### Second step: ponctuation filter, etc

```{r}
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removePunctuation)
#myCorpus <- tm_map(myCorpus, removeNumbers) dangerous because we might loose the cellphone model number
```

```{r}
toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))

myCorpus <- tm_map(myCorpus, toSpace, "/|@|ù|š|ø|ˆ|ƒ|€|™|â|\n|\\|")

```

### Third step: remove white space

```{r}
myCorpus <- tm_map(myCorpus, stripWhitespace)
```

### Fourth step: remove stop words

```{r}
myCorpus <- tm_map(myCorpus, removeWords, stopwords("english"))
myCorpus <- tm_map(myCorpus, stripWhitespace)
```

Let's print the first comment.
```{r}
myCorpus$content[1]
```
It looks OK. 

### Sixth: tokenizing

We are going to create unigrams, bigrams and trigrams.
First try:
```{r}
BigramTokenizer <- function(x) unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)

dtm_unigrams <- DocumentTermMatrix(myCorpus)
inspect(dtm_unigrams[1:10, 1:10])

dtm_bigrams <- DocumentTermMatrix(myCorpus, control = list(tokenize = BigramTokenizer))
inspect(dtm_bigrams[1:10, 1:10])
```
The bigrams matrix is the same ... so it failed!

Other try with other function:
```{r}
library(quanteda)
myCorpus_1gram <- tokens(myCorpus$content)
```
It does not work. Let's do the analysis for unigrams. 

### Seventh step: lemantization

Before the TF-IDF analysis, we have to lemantize the unigrams.

```{r}
library(tm)
library(textstem)
for (word in dtm_unigrams$dimnames$Terms){
  print(word)
  word <- lemmatize_words(word)
  print(word)
}
```


### Eighth step: term frequency


To reduce the dimension of the DTM, we can remove the less frequent terms such that the sparsity is less than 0.99

```{r}
review_dtm = removeSparseTerms(review_dtm, 0.99)
review_dtm
inspect(review_dtm[4,1:10])
```

Let's draw a word cloud:

```{r}
library(wordcloud)
freq = data.frame(sort(colSums(as.matrix(review_dtm)), decreasing=TRUE))
print(freq)
wordcloud(rownames(freq), freq[,1], max.words=50, colors=brewer.pal(1, "Dark2"))
```




